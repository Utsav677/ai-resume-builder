# Resume Builder Agent - Deployment Guide

## âœ… Implementation Complete!

All core features have been implemented:

- âœ… Profile extraction from resume text
- âœ… Job description analysis with OpenAI
- âœ… Content selection (experiences & projects)
- âœ… ATS optimization & scoring
- âœ… LaTeX resume generation
- âœ… PDF compilation
- âœ… Database persistence (SQLite â†’ PostgreSQL ready)
- âœ… JWT authentication system
- âœ… LangGraph workflow with 9 nodes

---

## ðŸŽ¯ Quick Start (Local Testing)

### 1. Test with LangGraph Studio

```bash
# Make sure your .env file has OPENAI_API_KEY set
langgraph dev
```

This will:
- Start LangGraph Studio on http://localhost:2024
- Open the chatbot interface
- Allow you to test the complete workflow

### 2. Test Workflow

**First-time user flow:**
1. Paste your resume
2. Agent extracts profile â†’ saved to database
3. Paste job description
4. Agent generates tailored resume with ATS score
5. Downloads LaTeX code + PDF (if pdflatex installed)

**Returning user flow:**
1. Agent detects existing profile
2. Paste job description
3. Resume generated immediately

---

## ðŸ“¦ What Was Built

### File Structure
```
resume-builder-agent/
â”œâ”€â”€ src/resume_agent/
â”‚   â”œâ”€â”€ graph.py              # LangGraph workflow (9 nodes)
â”‚   â”œâ”€â”€ nodes.py              # All node implementations
â”‚   â”œâ”€â”€ state.py              # State schema
â”‚   â”œâ”€â”€ latex_service.py      # LaTeX template filling & PDF compilation
â”‚   â”œâ”€â”€ database.py           # SQLAlchemy setup
â”‚   â”œâ”€â”€ models.py             # DB models (User, UserProfile, ResumeGeneration)
â”‚   â”œâ”€â”€ user_service.py       # Profile CRUD operations
â”‚   â”œâ”€â”€ auth.py               # JWT authentication
â”‚   â”œâ”€â”€ schemas.py            # Pydantic validation models
â”‚   â””â”€â”€ config.py             # Environment config
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ resume_template.tex   # ATS-friendly LaTeX template
â”œâ”€â”€ outputs/                  # Generated PDFs (created automatically)
â”œâ”€â”€ langgraph.json           # LangGraph deployment config
â””â”€â”€ pyproject.toml           # Python dependencies
```

### LangGraph Workflow

```
START
  â†“
check_profile
  â”œâ”€â†’ [No Profile] â†’ extract_profile â†’ get_job_input
  â””â”€â†’ [Has Profile] â†’ get_job_input
                          â†“
                     [Paste Job Description]
                          â†“
                      analyze_job
                          â†“
                     select_content (rank experiences/projects)
                          â†“
                     optimize_ats (calculate ATS score)
                          â†“
                     generate_latex
                          â†“
                      compile_pdf
                          â†“
                       complete
                          â†“
                         END
```

---

## ðŸš€ GCP Deployment Guide

### Prerequisites

1. **Install LaTeX for PDF Compilation:**
   - Windows: Install MiKTeX from https://miktex.org/download
   - Mac: Install MacTeX from https://www.tug.org/mactex/
   - Linux: `sudo apt-get install texlive-full`

2. **Install gcloud CLI:**
   - Download from https://cloud.google.com/sdk/docs/install
   - Run: `gcloud auth login`

### Step 1: Create GCP Project

```bash
# Create project
gcloud projects create resume-builder-prod --name="Resume Builder"

# Set as active project
gcloud config set project resume-builder-prod

# Enable required APIs
gcloud services enable \
  run.googleapis.com \
  sqladmin.googleapis.com \
  secretmanager.googleapis.com
```

### Step 2: Setup Cloud SQL (PostgreSQL)

```bash
# Create PostgreSQL instance
gcloud sql instances create resume-builder-db \
  --database-version=POSTGRES_15 \
  --tier=db-f1-micro \
  --region=us-central1

# Create database
gcloud sql databases create resume_builder_db \
  --instance=resume-builder-db

# Set root password
gcloud sql users set-password postgres \
  --instance=resume-builder-db \
  --password=YOUR_SECURE_PASSWORD

# Get connection name (save this!)
gcloud sql instances describe resume-builder-db --format="value(connectionName)"
```

### Step 3: Update Environment Variables

Create/update your `.env` file:

```env
# OpenAI
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# Database (for production - use Cloud SQL connection string)
DATABASE_URL=postgresql://postgres:YOUR_PASSWORD@/resume_builder_db?host=/cloudsql/YOUR_PROJECT:REGION:INSTANCE_NAME

# JWT Auth
JWT_SECRET_KEY=your-super-secret-random-string-here
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=10080

# Default user for LangGraph Studio
DEFAULT_USER_ID=default-user-123
```

### Step 4: Deploy to LangGraph Cloud

Option A: **Using LangGraph CLI (Recommended)**

```bash
# Install LangGraph CLI
pip install langgraph-cli

# Deploy
langgraph deploy --project resume-builder-prod
```

Option B: **Using Docker + Cloud Run**

```bash
# Build Docker image
docker build -t gcr.io/resume-builder-prod/resume-agent .

# Push to GCR
docker push gcr.io/resume-builder-prod/resume-agent

# Deploy to Cloud Run
gcloud run deploy resume-agent \
  --image gcr.io/resume-builder-prod/resume-agent \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --add-cloudsql-instances YOUR_CONNECTION_NAME \
  --set-env-vars OPENAI_API_KEY=$OPENAI_API_KEY
```

### Step 5: Store Secrets in Secret Manager

```bash
# Store OpenAI API key
echo -n "sk-your-key" | gcloud secrets create openai-api-key --data-file=-

# Store JWT secret
echo -n "your-jwt-secret" | gcloud secrets create jwt-secret --data-file=-

# Store database URL
echo -n "postgresql://..." | gcloud secrets create database-url --data-file=-
```

---

## ðŸ”§ Local Development

### Running Locally

```bash
# Install dependencies
pip install -e .

# Initialize database
python src/resume_agent/init_db.py

# Run with LangGraph Studio
langgraph dev

# Or test individual components
python -c "from src.resume_agent.graph import graph; print('Graph OK!')"
```

### Testing Without PDF Compilation

If you don't have LaTeX installed, the agent will still:
- Generate LaTeX code (viewable in chat)
- Return the code as text
- You can copy/paste into Overleaf.com to compile

---

## ðŸ—ï¸ Next.js Frontend (Optional)

If you want to build a custom frontend instead of using LangGraph Studio:

### Setup

```bash
npx create-next-app@latest resume-builder-frontend
cd resume-builder-frontend
npm install @langchain/langgraph-sdk
```

### Example API Integration

```typescript
import { Client } from "@langchain/langgraph-sdk";

const client = new Client({
  apiUrl: "https://your-langgraph-deployment.com"
});

// Start a new thread
const thread = await client.threads.create();

// Send message
await client.runs.stream(thread.thread_id, "resume_builder", {
  input: {
    messages: [{ role: "human", content: "Here's my resume..." }]
  }
});
```

### Deploy Frontend

```bash
# Deploy to Vercel (easiest)
vercel deploy

# Or Firebase Hosting
firebase init hosting
firebase deploy
```

---

## ðŸ“Š Database Schema

### Tables Created

1. **users** - Authentication
   - user_id (PK)
   - email
   - hashed_password
   - created_at, updated_at

2. **user_profiles** - Resume data
   - profile_id (PK)
   - user_id (FK)
   - full_name, email, phone, location
   - linkedin_url, github_url, portfolio_url
   - education (JSON)
   - experience (JSON)
   - projects (JSON)
   - technical_skills (JSON)
   - awards (JSON)

3. **resume_generations** - Generated resumes
   - generation_id (PK)
   - user_id (FK)
   - job_title, company_name
   - job_description (TEXT)
   - tailored_content (JSON)
   - ats_keywords (JSON)
   - ats_score (FLOAT)
   - latex_code (TEXT)
   - pdf_path (STRING)
   - created_at

4. **conversation_threads** - LangGraph checkpoints
   - thread_id (PK)
   - user_id (FK)
   - session_type
   - created_at

---

## ðŸ› Troubleshooting

### PDF Compilation Fails

**Error:** `pdflatex not found`

**Solution:** Install LaTeX distribution:
- Windows: MiKTeX
- Mac: MacTeX
- Linux: `sudo apt install texlive-full`

Or use Overleaf.com with the generated LaTeX code.

### Import Errors

**Error:** `ModuleNotFoundError: No module named 'X'`

**Solution:**
```bash
pip install -e .
pip install email-validator python-jose[cryptography] passlib[bcrypt]
```

### Database Connection Issues

**Error:** `could not connect to database`

**Solution:**
- Local: Check `DATABASE_URL` in `.env` points to SQLite
- Production: Verify Cloud SQL connection string format
- Ensure Cloud SQL Proxy is running if testing Cloud SQL locally

### LangGraph Studio Not Loading

**Error:** Graph won't load in Studio

**Solution:**
```bash
# Test graph loads
python -c "from src.resume_agent.graph import graph; print('OK')"

# Check langgraph.json points to correct path
cat langgraph.json

# Restart Studio
langgraph dev
```

---

## ðŸ“ Testing Checklist

Before deploying to production:

- [ ] Test profile extraction with sample resume
- [ ] Test job analysis with real job description
- [ ] Verify ATS score calculation
- [ ] Check LaTeX generation (no syntax errors)
- [ ] Test PDF compilation locally
- [ ] Verify database writes (check resume_generations table)
- [ ] Test returning user flow (profile already exists)
- [ ] Check error handling (malformed inputs)
- [ ] Test with long resume (>5 pages)
- [ ] Validate LaTeX special character escaping

---

## ðŸŽ‰ What's Working

âœ… Complete end-to-end resume generation pipeline
âœ… ATS optimization with keyword matching
âœ… Smart content selection based on job requirements
âœ… Professional LaTeX template (Jake Gutierrez format)
âœ… Database persistence with SQLAlchemy
âœ… JWT authentication ready for frontend
âœ… LangGraph checkpointing for conversation state
âœ… Error handling throughout pipeline

---

## ðŸ“š Additional Resources

- LangGraph Docs: https://langchain-ai.github.io/langgraph/
- LangGraph Cloud: https://www.langchain.com/langgraph-cloud
- Overleaf (LaTeX editor): https://www.overleaf.com/
- GCP Cloud Run: https://cloud.google.com/run
- ATS Best Practices: https://www.jobscan.co/

---

## ðŸ”‘ Key Files to Know

- **langgraph.json** - Deployment config (points to your graph)
- **.env** - API keys and secrets (NEVER commit this!)
- **templates/resume_template.tex** - Customize resume layout here
- **src/resume_agent/nodes.py** - Modify AI prompts and logic here
- **src/resume_agent/latex_service.py** - LaTeX formatting rules

---

## ðŸ’¡ Tips

1. **Test with your own resume first** - Best way to verify extraction quality
2. **Check ATS score thresholds** - Adjust in `ats_optimization_node` if needed
3. **Customize LaTeX template** - The template is in `templates/resume_template.tex`
4. **Monitor OpenAI costs** - Each resume generation uses ~3-5 API calls
5. **Use gpt-4o-mini for cost efficiency** - Already configured as default

---

**You're all set! Run `langgraph dev` to start testing your agent.**
